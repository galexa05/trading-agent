{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "948a672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to the top of your notebook for auto-reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b61c310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from scripts.collect_articles import NewsDataCollector\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6972e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/stock_portfolios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c471ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'{DATA_DIR}/portfolio_articles.pkl', 'rb') as f:\n",
    "    article_dict = pickle.load(f)\n",
    "\n",
    "with open(f'{DATA_DIR}/article_id_full_context.pkl', 'rb') as f:\n",
    "    article_full_context = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d550aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "def extract_article_fields(article_dict: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract specified fields from a dictionary of articles and return as a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        article_dict (Dict[str, Any]): Dictionary where key is article_id and value is a dict of article metadata.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with one row per article and columns for selected fields.\n",
    "    \"\"\"\n",
    "    fields = [\n",
    "        'article_id', 'pubDate', 'pubDateTZ', 'title', 'link', 'creator',\n",
    "        'description', 'source_id', 'source_name', 'source_url', 'source_icon'\n",
    "    ]\n",
    "    data = []\n",
    "    for article_id, item in article_dict.items():\n",
    "        row = []\n",
    "        for field in fields:\n",
    "            if field == 'article_id':\n",
    "                row.append(article_id)\n",
    "            elif field == 'creator':\n",
    "                creators = item.get(field, [])\n",
    "                if isinstance(creators, list):\n",
    "                    row.append(' | '.join(str(c) for c in creators))\n",
    "                else:\n",
    "                    row.append(str(creators) if creators is not None else '')\n",
    "            else:\n",
    "                row.append(item.get(field, ''))\n",
    "        data.append(row)\n",
    "    df = pd.DataFrame(data, columns=fields)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8115d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = extract_article_fields(article_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71ec738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, Any\n",
    "\n",
    "def articles_to_dataframe(article_dict: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a dictionary of articles into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        article_dict (Dict[str, Any]): Dictionary mapping article IDs to their information.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns: article_id, title, summary, text.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    # Iterate through each article and extract relevant fields\n",
    "    for article_id, info in article_dict.items():\n",
    "        data.append({\n",
    "            'article_id': article_id,\n",
    "            # 'title': info.get('title', ''),\n",
    "            'summary': info.get('summary', ''),\n",
    "            'text': info.get('text', '')\n",
    "        })\n",
    "    # Create and return a DataFrame from the extracted data\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e39f584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_context_df = articles_to_dataframe(article_full_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5bfa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = \\\n",
    "pd.merge(\n",
    "    article_df,\n",
    "    full_context_df,\n",
    "    on='article_id',\n",
    "    how = 'left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d09c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(f'{DATA_DIR}/articles.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading-agent-Iwjhydeb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
